{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralMachineTranslation_En-Pt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW7iJsQNEbU8",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNX14AtvEprj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrow0G4TEr2W",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "http://www.manythings.org/anki/por-eng.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8d8P4NE8B1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "###From Upload System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ie07vjD35X",
        "colab_type": "code",
        "outputId": "de1df4e9-a9d4-4655-8c2a-d618a9910115",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6166ee9d-2c0c-4bfa-9cd5-11fb17338aeb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6166ee9d-2c0c-4bfa-9cd5-11fb17338aeb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving por2.txt to por2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VRaB4uFFSR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('por.txt', mode='rt', encoding='utf-8')\n",
        "data = file.read()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsvLUZUC_TaO",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QZIDZaC_A4n",
        "colab_type": "text"
      },
      "source": [
        "###Split lines and phrases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxxGatPo6hJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = data.strip().split('\\n')\n",
        "pairs = [line.split('\\t') for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5oTqs1_4Uo",
        "colab_type": "text"
      },
      "source": [
        "###Clean lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edbprNCOJfbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned = list()\n",
        "re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "for pair in pairs:\n",
        "  clean_pair = list()\n",
        "  for line in pair:\n",
        "    # normalize unicode characters\n",
        "    line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "    line = line.decode('UTF-8')\n",
        "    # tokenize on white space\n",
        "    line = line.split()\n",
        "    # convert to lowercase\n",
        "    line = [word.lower() for word in line]\n",
        "    # remove punctuation from each token\n",
        "    line = [word.translate(table) for word in line]\n",
        "    # remove non-printable chars form each token\n",
        "    line = [re_print.sub('', w) for w in line]\n",
        "    # remove tokens with numbers in them\n",
        "    line = [word for word in line if word.isalpha()]\n",
        "    # store as string\n",
        "    clean_pair.append(' '.join(line))\n",
        "  cleaned.append(clean_pair)\n",
        "\n",
        "pairs_cleaned = array(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2imz1YrL-Ft",
        "colab_type": "text"
      },
      "source": [
        "###Save cleaned text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvvDIqKiMDcO",
        "colab_type": "code",
        "outputId": "19deb40f-22ac-4fe8-ca33-141a20cb1299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def save_data(data, filename):\n",
        "  dump(data, open(filename, 'wb'))\n",
        "  print('Saved: %s' % filename)\n",
        "\n",
        "save_data(pairs_cleaned, 'eng-por.pkl')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: eng-por.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6S9SHZ4NX8E",
        "colab_type": "code",
        "outputId": "9b9bd143-ed32-47ff-ad8f-adb718139548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(100):\n",
        "  print('[%s] => [%s]' % (pairs_cleaned[i,0], pairs_cleaned[i,1]))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[go] => [vai]\n",
            "[go] => [va]\n",
            "[hi] => [oi]\n",
            "[run] => [corre]\n",
            "[run] => [corra]\n",
            "[run] => [corram]\n",
            "[run] => [corre]\n",
            "[run] => [corra]\n",
            "[run] => [corram]\n",
            "[who] => [quem]\n",
            "[who] => [que]\n",
            "[wow] => [uau]\n",
            "[wow] => [nossa]\n",
            "[wow] => [wow]\n",
            "[fire] => [fogo]\n",
            "[help] => [ajuda]\n",
            "[help] => [socorro]\n",
            "[jump] => [pule]\n",
            "[jump] => [pulem]\n",
            "[jump] => [pule]\n",
            "[stop] => [pare]\n",
            "[stop] => [parem]\n",
            "[wait] => [espere]\n",
            "[wait] => [espere]\n",
            "[wait] => [esperem]\n",
            "[go on] => [va]\n",
            "[hello] => [oi]\n",
            "[hello] => [alo]\n",
            "[hello] => [ola]\n",
            "[hello] => [alo]\n",
            "[i ran] => [eu corri]\n",
            "[i see] => [estou vendo]\n",
            "[i try] => [eu tento]\n",
            "[i try] => [tento]\n",
            "[i won] => [ganhei]\n",
            "[i won] => [eu venci]\n",
            "[oh no] => [ah nao]\n",
            "[relax] => [relaxe]\n",
            "[relax] => [relaxa]\n",
            "[shoot] => [tiro]\n",
            "[smile] => [sorria]\n",
            "[smile] => [sorriam]\n",
            "[attack] => [atacar]\n",
            "[attack] => [ataquem]\n",
            "[attack] => [ataque]\n",
            "[cheers] => [saude]\n",
            "[freeze] => [parado]\n",
            "[get up] => [levantese]\n",
            "[get up] => [levantemse]\n",
            "[get up] => [levantate]\n",
            "[get up] => [levantese]\n",
            "[get up] => [levantate]\n",
            "[go now] => [va agora]\n",
            "[got it] => [entendi]\n",
            "[got it] => [eu entendi]\n",
            "[got it] => [saquei]\n",
            "[got it] => [entendeu]\n",
            "[he ran] => [ele correu]\n",
            "[he ran] => [ele corria]\n",
            "[hop in] => [sobe ai]\n",
            "[hop in] => [entra ai]\n",
            "[hug me] => [me abrace]\n",
            "[i fell] => [eu cai]\n",
            "[i know] => [eu sei]\n",
            "[i know] => [sei]\n",
            "[i left] => [eu sai]\n",
            "[i paid] => [eu paguei]\n",
            "[i quit] => [eu me demito]\n",
            "[i work] => [eu estou trabalhando]\n",
            "[im ok] => [estou bem]\n",
            "[im ok] => [eu vou bem]\n",
            "[im up] => [estou acordado]\n",
            "[listen] => [escute]\n",
            "[listen] => [oucame]\n",
            "[listen] => [escuta]\n",
            "[listen] => [escutem]\n",
            "[listen] => [ouca isso]\n",
            "[listen] => [escutemme]\n",
            "[listen] => [escute]\n",
            "[listen] => [escuta]\n",
            "[listen] => [escutem]\n",
            "[listen] => [escutai]\n",
            "[no way] => [de jeito nenhum]\n",
            "[no way] => [impossivel]\n",
            "[no way] => [de maneira alguma]\n",
            "[no way] => [de modo algum]\n",
            "[no way] => [sem chance]\n",
            "[really] => [serio]\n",
            "[really] => [e mesmo]\n",
            "[really] => [mesmo]\n",
            "[really] => [e serio]\n",
            "[thanks] => [obrigado]\n",
            "[thanks] => [obrigada]\n",
            "[thanks] => [obrigado]\n",
            "[thanks] => [obrigada]\n",
            "[try it] => [tentao]\n",
            "[try it] => [proveo]\n",
            "[try it] => [provea]\n",
            "[we try] => [tentamos]\n",
            "[we try] => [nos tentamos]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVZG3EqRnJY",
        "colab_type": "text"
      },
      "source": [
        "##Train/Test Separation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJItOhB-TbxS",
        "colab_type": "code",
        "outputId": "ba79fdca-230c-4903-e9a4-e49072a452b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "n_sentences = 10000\n",
        "dataset = pairs_cleaned[:n_sentences, :]\n",
        "# random shuffle\n",
        "shuffle(dataset)\n",
        "# split into train/test\n",
        "train, test = dataset[:9000], dataset[9000:]\n",
        "# save\n",
        "save_data(dataset, 'eng-por-both.pkl')\n",
        "save_data(train, 'eng-por-train.pkl')\n",
        "save_data(test, 'eng-por-test.pkl')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: eng-por-both.pkl\n",
            "Saved: eng-por-train.pkl\n",
            "Saved: eng-por-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Bh4WQ_XR4r",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6823RGOMXU15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAeLmzEWatiy",
        "colab_type": "text"
      },
      "source": [
        "## Max Lenght"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgoQR7FlawwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvI65ElObIpY",
        "colab_type": "code",
        "outputId": "3ecf6dda-b1cc-456d-d55c-0523c048fc8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare portuguese tokenizer\n",
        "por_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "por_vocab_size = len(por_tokenizer.word_index) + 1\n",
        "por_length = max_length(dataset[:, 1])\n",
        "print('Portuguese Vocabulary Size: %d' % por_vocab_size)\n",
        "print('Portuguese Max Length: %d' % (por_length))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 3570\n",
            "English Max Length: 9\n",
            "Portuguese Vocabulary Size: 5252\n",
            "Portuguese Max Length: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMQqWckAhuIc",
        "colab_type": "text"
      },
      "source": [
        "#Neural Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0fpftarvQv",
        "colab_type": "text"
      },
      "source": [
        "##Encode with one hot encode (word embedding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUvp7q4HhxLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sequences(tokenizer, length, lines):\n",
        "  X = tokenizer.texts_to_sequences(lines)\n",
        "  X = pad_sequences(X, maxlen=length, padding='post')\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpq3mKOCtglj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_output(sequences, vocab_size):\n",
        "  ylist = list()\n",
        "  for sequence in sequences:\n",
        "    encoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "    ylist.append(encoded)\n",
        "  y = array(ylist)\n",
        "  y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUZu_EkxndZ",
        "colab_type": "text"
      },
      "source": [
        "##Prepare test and training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bY0hafyxrIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = encode_sequences(eng_tokenizer, eng_length, train[:,0])\n",
        "trainY = encode_sequences(por_tokenizer, por_length, train[:,1])\n",
        "trainY = encode_output(trainY, por_vocab_size)\n",
        "\n",
        "testX = encode_sequences(eng_tokenizer, eng_length, test[:,0])\n",
        "testY = encode_sequences(por_tokenizer, por_length, test[:,1])\n",
        "testY = encode_output(testY, por_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swt0xw2D8k1l",
        "colab_type": "text"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0uNPMwS8pRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "  model.add(LSTM(n_units))\n",
        "  model.add(RepeatVector(tar_timesteps))\n",
        "  model.add(LSTM(n_units, return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PMQyVQ-0Qw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "e06b3244-7f57-4ef9-9a09-9931b295271d"
      },
      "source": [
        "model = define_model(eng_vocab_size, por_vocab_size, eng_length, por_length, 256)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "print(model.summary())\n",
        "#plot_model(model, to_file='model.png', show_shapes=True)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 9, 256)            913920    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 12, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 12, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 12, 5252)          1349764   \n",
            "=================================================================\n",
            "Total params: 3,314,308\n",
            "Trainable params: 3,314,308\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTx1kpnXAs15",
        "colab_type": "text"
      },
      "source": [
        "##Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDidyzXLAvLc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "510b4483-64d3-4f5a-9db5-ac83c942382a"
      },
      "source": [
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 69s - loss: 3.5600 - val_loss: 2.8094\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.80940, saving model to model.h5\n",
            "Epoch 2/30\n",
            " - 65s - loss: 2.7342 - val_loss: 2.7419\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.80940 to 2.74192, saving model to model.h5\n",
            "Epoch 3/30\n",
            " - 66s - loss: 2.6428 - val_loss: 2.6906\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.74192 to 2.69058, saving model to model.h5\n",
            "Epoch 4/30\n",
            " - 65s - loss: 2.5871 - val_loss: 2.6776\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.69058 to 2.67759, saving model to model.h5\n",
            "Epoch 5/30\n",
            " - 68s - loss: 2.5426 - val_loss: 2.6527\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.67759 to 2.65270, saving model to model.h5\n",
            "Epoch 6/30\n",
            " - 67s - loss: 2.5034 - val_loss: 2.6423\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.65270 to 2.64231, saving model to model.h5\n",
            "Epoch 7/30\n",
            " - 67s - loss: 2.4692 - val_loss: 2.6165\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.64231 to 2.61648, saving model to model.h5\n",
            "Epoch 8/30\n",
            " - 67s - loss: 2.4325 - val_loss: 2.5848\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.61648 to 2.58480, saving model to model.h5\n",
            "Epoch 9/30\n",
            " - 66s - loss: 2.3900 - val_loss: 2.5664\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.58480 to 2.56645, saving model to model.h5\n",
            "Epoch 10/30\n",
            " - 67s - loss: 2.3451 - val_loss: 2.5328\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.56645 to 2.53276, saving model to model.h5\n",
            "Epoch 11/30\n",
            " - 64s - loss: 2.2955 - val_loss: 2.5000\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.53276 to 2.50000, saving model to model.h5\n",
            "Epoch 12/30\n",
            " - 62s - loss: 2.2453 - val_loss: 2.4667\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.50000 to 2.46671, saving model to model.h5\n",
            "Epoch 13/30\n",
            " - 62s - loss: 2.1887 - val_loss: 2.4403\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.46671 to 2.44031, saving model to model.h5\n",
            "Epoch 14/30\n",
            " - 63s - loss: 2.1327 - val_loss: 2.4510\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.44031\n",
            "Epoch 15/30\n",
            " - 63s - loss: 2.0946 - val_loss: 2.3803\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.44031 to 2.38033, saving model to model.h5\n",
            "Epoch 16/30\n",
            " - 65s - loss: 2.0276 - val_loss: 2.3419\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.38033 to 2.34193, saving model to model.h5\n",
            "Epoch 17/30\n",
            " - 64s - loss: 1.9672 - val_loss: 2.3318\n",
            "\n",
            "Epoch 00017: val_loss improved from 2.34193 to 2.33181, saving model to model.h5\n",
            "Epoch 18/30\n",
            " - 64s - loss: 1.9096 - val_loss: 2.3245\n",
            "\n",
            "Epoch 00018: val_loss improved from 2.33181 to 2.32454, saving model to model.h5\n",
            "Epoch 19/30\n",
            " - 63s - loss: 1.8541 - val_loss: 2.2821\n",
            "\n",
            "Epoch 00019: val_loss improved from 2.32454 to 2.28212, saving model to model.h5\n",
            "Epoch 20/30\n",
            " - 64s - loss: 1.7995 - val_loss: 2.2633\n",
            "\n",
            "Epoch 00020: val_loss improved from 2.28212 to 2.26331, saving model to model.h5\n",
            "Epoch 21/30\n",
            " - 63s - loss: 1.7447 - val_loss: 2.2373\n",
            "\n",
            "Epoch 00021: val_loss improved from 2.26331 to 2.23726, saving model to model.h5\n",
            "Epoch 22/30\n",
            " - 62s - loss: 1.6903 - val_loss: 2.2273\n",
            "\n",
            "Epoch 00022: val_loss improved from 2.23726 to 2.22730, saving model to model.h5\n",
            "Epoch 23/30\n",
            " - 63s - loss: 1.6382 - val_loss: 2.2063\n",
            "\n",
            "Epoch 00023: val_loss improved from 2.22730 to 2.20627, saving model to model.h5\n",
            "Epoch 24/30\n",
            " - 63s - loss: 1.5865 - val_loss: 2.1985\n",
            "\n",
            "Epoch 00024: val_loss improved from 2.20627 to 2.19847, saving model to model.h5\n",
            "Epoch 25/30\n",
            " - 62s - loss: 1.5305 - val_loss: 2.1774\n",
            "\n",
            "Epoch 00025: val_loss improved from 2.19847 to 2.17742, saving model to model.h5\n",
            "Epoch 26/30\n",
            " - 63s - loss: 1.4770 - val_loss: 2.1577\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.17742 to 2.15770, saving model to model.h5\n",
            "Epoch 27/30\n",
            " - 64s - loss: 1.4253 - val_loss: 2.1467\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.15770 to 2.14667, saving model to model.h5\n",
            "Epoch 28/30\n",
            " - 66s - loss: 1.3721 - val_loss: 2.1406\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.14667 to 2.14065, saving model to model.h5\n",
            "Epoch 29/30\n",
            " - 65s - loss: 1.3196 - val_loss: 2.1252\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.14065 to 2.12516, saving model to model.h5\n",
            "Epoch 30/30\n",
            " - 67s - loss: 1.2659 - val_loss: 2.1220\n",
            "\n",
            "Epoch 00030: val_loss improved from 2.12516 to 2.12197, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0f8509be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}